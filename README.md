# ğŸŒ Web Data Extraction & AI-Powered Analysis Tool

A powerful yet user-friendly **web scraping and AI analysis** tool built with **Flask**, designed to extract clean and structured data from web pages, analyze it with an **LLM (GROQ API)**, and download results in CSV/Excel format.  
This project combines **web scraping, data processing, and AI** to assist with research, e-commerce analysis, and general data extraction tasks.

---

## ğŸ“Œ Features

- **Multiple Extraction Modes**
  - **Extract Full Page (Tables, Headings)** â€“ For rich table & structured HTML data.
  - **Extract Clean Text (AI/NLP)** â€“ For natural language content extraction.
  - **Extract by HTML Tags** â€“ For advanced, targeted scraping.

- **LLM-Powered Queries**
  - Ask questions about the extracted content.
  - Get answers in a **formatted HTML table**.
  - Export LLM-generated tables in CSV/Excel.

- **Data Export**
  - Download extracted data or LLM results as **CSV** or **Excel**.

- **Foldable Extracted Text Box**
  - Keeps UI clean and professional.

- **Secure API Keys**
  - Uses `.env` to store secrets like `GROQ_API_KEY`.

---

## ğŸ“¸ Demo Preview

### 1ï¸âƒ£ Wikipedia GDP Data (Professional / Data Analysis) 

**Step 1 â€” Extracting product data** 

![Wikipedia GDP Demo - Extraction](assets/wikipedia_gdp_demo1.gif)

**Step 2 â€” AI-powered analysis**  

![Wikipedia GDP Demo - AI](assets/wikipedia_gdp_demo2.gif)

---

### 2ï¸âƒ£ Books to Scrape (E-commerce Data Extraction) 

**Step 1 â€” Extracting data** 

![Books to Scrape Demo - Extraction](assets/books_to_scrape_demo1.gif)

**Step 2 â€” AI-powered analysis**  

![Books to Scrape Demo - AI](assets/books_to_scrape_demo2.gif)

---

## ğŸ›  Tech Stack
- **Backend:** Flask (Python)
- **Web Scraping:** BeautifulSoup4, lxml, Playwright
- **Data Processing:** Pandas, OpenPyXL
- **AI/LLM:** GROQ API
- **Frontend:** HTML, CSS, JavaScript
- **Markdown Rendering:** python-markdown2
- **Export Formats:** CSV, Excel

---

## ğŸ“¥ Installation

# 1ï¸âƒ£ Clone the repository
git clone https://github.com/Akash-Sare03/web-scraper-ai-analysis.git
cd web-scraper-ai-analysis

# 2ï¸âƒ£ Create a virtual environment
python -m venv venv
source venv/bin/activate   # On Mac/Linux
venv\Scripts\activate      # On Windows

# 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

# 4ï¸âƒ£ Create a .env file and add your API key
echo "GROQ_API_KEY=your_api_key_here" > .env

# 5ï¸âƒ£ Run the Flask server
python app.py

---

## ğŸš€ Usage

- Open the app in your browser: http://127.0.0.1:5000/

- Choose one of the three extraction modes:

- Extract Full Page â€” Best for tables and headings

- Extract Clean Text â€” Best for NLP/AI text analysis

- Extract by HTML Tags â€” Advanced scraping for specific elements

- Click Extract to view results.

- (Optional) Ask AI questions based on extracted data.

- Download results in CSV or Excel.

---

## ğŸ§  Core Concepts

- **HTML Parsing:** Using BeautifulSoup and lxml for precise element targeting.

- **Dynamic Pages:** Handled via Playwright for JavaScript-rendered content.

- **Data Cleaning:** Removing duplicates, hidden elements, and noise.

- **AI Integration:** Sending extracted text to a GROQ LLM for advanced analysis.

- **Export Handling:** Using Pandas to create structured CSV/Excel files.

---


- **ğŸ”’ Security Notes:** Respect websites 'robots.txt' and terms of service before scraping.


---

## ğŸ¤ Credits

- Built by [Akash Sare](https://github.com/Akash-Sare03)
- Thanks to open-source contributors for libraries used





